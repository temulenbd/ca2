{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51d04671",
   "metadata": {},
   "source": [
    "                                                                       TEMUULEN Bulgan - 2022427"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf25cb4",
   "metadata": {},
   "source": [
    "### CCT College Dublin Continuous Assessment No.2\n",
    "# AN ANALYSIS OF INDIAN FARMERS' PROTEST TWEETS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ad4ca0",
   "metadata": {},
   "source": [
    "**Brief Introduction of the project:**\n",
    "\n",
    "1. For my second continuous assessment, I choose CSV format data of Indian Farmer's Protest Tweets. This file contains over 1 million English language tweets tweeted between November 1st, 2020 and november 21st, 2021 with the hashtag <#FarmersProtest>. It is downloaded from the Kaggle website with the CCO:Public Domain license.\n",
    "(https://kaggle.com/datasets/prathamsharma123/farmers-protest-tweets-dataset-csv)\n",
    "\n",
    "2. I divided my project into 3 primary sections (Every step in data processing and analysis is fully discussed on each subsection of these primary sections.):\n",
    "    1. big data storage and processing\n",
    "    2. comparative analysis of databases\n",
    "    3. sentiment analysis and forecast\n",
    "\n",
    "3. I used Git for daily code tracking and GitHub for archiving, monitoring and sharing. To view the whole project on GitHub, click on the follwig link "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb3b7ce",
   "metadata": {},
   "source": [
    "**Libraries and modules used for this project:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97d4f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de876cf9",
   "metadata": {},
   "source": [
    "## 1. Big Data Storage and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf80edbb",
   "metadata": {},
   "source": [
    "For my second continous project I choose Kaggle.com's dataset called 'Farmers Protest Tweets'. It was collected by the hashtag #FarmersProtest including CCO:Pulic Domain license which means that this dataset allows copy, modify, distribute and perform the work, even for commercial purpososes, all without asking permission. All the tweets in it in English Language and collected from Twitter.com from November 1st, 2020 to November 21st, 2021. The main subject matter of these tweets are about the biggest anti-farm laws protest which took place at the borders of the Indian natioanl capital of New Delhi, organized by coalition of over 40 farmer from across the country.The dataset extraction process was done by Pratham Sharma, kaggle datasets expert who used Twitter API and  snscrape Python library for collection. The tweets data consist of two separate CSVL files with size the size of 1.7Â GB and 81.2 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47471a04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking the file size of the file.\n",
    "file_size = os.path.getsize('/home/hduser/Desktop/ca/tweets.csv')/(1024*1024*1024)\n",
    "print(f'The size of the tweets file is: {file_size:.2f} GB.')\n",
    "file_size = os.path.getsize('/home/hduser/Desktop/ca/users.csv')/(1024*1024)\n",
    "print(f'The size of the users file is: {file_size:.2f} MB.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b503dd",
   "metadata": {},
   "source": [
    "### 1.1. *Preprocessing in Python.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83926380",
   "metadata": {},
   "source": [
    "Before to start processing the DataSet in distributed file system platforms I decided to examine each CSV file using Pandas on Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53351e86",
   "metadata": {},
   "source": [
    "***tweets.csv***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9151b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame.\n",
    "df_tweets = pd.read_csv('/home/hduser/Desktop/ca/tweets.csv')\n",
    "\n",
    "# Checking the DataFrame.\n",
    "df_tweets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9fc0c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Printing information about the DataFrame\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63926d09",
   "metadata": {},
   "source": [
    "***users.csv***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame.\n",
    "df_users = pd.read_csv('/home/hduser/Desktop/ca/users.csv')\n",
    "\n",
    "# Checking the DataFrame.\n",
    "df_users.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabf86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing information about the DataFrame\n",
    "df_users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3dfac9",
   "metadata": {},
   "source": [
    "As we can see from abowe four code sells the DataSet with tweets consisted of 13 distinct columns of information where some of which is not very importand for further processing. The columns such as 'tweetUrl', 'tweetId', 'source', 'media', 'retweetedTweet', 'quotedTweet', 'mentionedUsers', and 'userId' doesn't include importand information for analysis.\n",
    "\n",
    "On the other hand DataSet with users information consisted of 18 distincst columns of information from which I can only use only column with 'display name. So further I'm going to remove unnessecary columns from each DataFrame and merge them as one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac869a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Deleting columns from the DataFrame of tweets.\n",
    "df_tweets = df_tweets.drop(labels=['tweetUrl', 'tweetId', 'source', 'media', 'retweetedTweet', 'quotedTweet', \\\n",
    "                                           'mentionedUsers'], axis=1)\n",
    "\n",
    "# Checking the changes.\n",
    "df_tweets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting columns from the DataFrame of tweets.\n",
    "df_users = df_users[['displayname', 'userId']]\n",
    "\n",
    "# Checking the changes.\n",
    "df_users.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2026b755",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Performing left merging on two DataFrames.\n",
    "df_final = pd.merge(df_tweets, df_users, on='userId', how='left')\n",
    "\n",
    "# Deleting the column 'userId'.\n",
    "df_final = df_final.drop(labels=['userId'], axis=1)\n",
    "\n",
    "# Checking the changes.\n",
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8823631b",
   "metadata": {},
   "source": [
    "I merged two DataFrames and removed unessary columns. Now I'm going to save the it as a CSV file on my Ubuntu VM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the DataFrame as 'new_tweets.csv' on my VM with the utf-8 Encoding.\n",
    "df_final.to_csv('/home/hduser/Desktop/ca/new_tweets.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ce26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the file size.\n",
    "new_file_size = os.path.getsize('/home/hduser/Desktop/ca/new_tweets.csv')/(1024*1024)\n",
    "print(f'The size of new tweet file is: {new_file_size:.2f} MB.')\n",
    "\n",
    "print(df_final.shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11069657",
   "metadata": {},
   "source": [
    "The file size is reduced from 1.7GB to 670.2MB and it still have importand information of the tweets for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5681470",
   "metadata": {},
   "source": [
    "### 1.2 *Data cleaning in Pyspark.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058322bc",
   "metadata": {},
   "source": [
    "I desided to store my new created twitter dataset file in HDFS and before doing EDA and sentiment analysis I'll further do more thorough preprocessing using Apache Spark tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8babcb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting a new SparkSession for data import from HDFS.\n",
    "spark = SparkSession.builder \\\n",
    "        .appName('HDFS Data Import') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a896a58e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading the file.\n",
    "df_spark = spark.read.option('header', 'true') \\\n",
    "                        .option('multiline', 'true') \\\n",
    "                        .option('quote', \"\\\"\") \\\n",
    "                        .option('escape', \"\\\"\") \\\n",
    "                        .csv('/ca2/new_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542642c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+------------+---------+----------+--------------------+\n",
      "|                date|     renderedContent|replyCount|retweetCount|likeCount|quoteCount|         displayname|\n",
      "+--------------------+--------------------+----------+------------+---------+----------+--------------------+\n",
      "|2021-03-30 03:33:...|Support ðŸ‘‡\\n\\n#Fa...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:33:...|Supporting farmer...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:31:...|Support farmers i...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:30:...|#StopHateAgainstF...|         0|           1|        3|         0|       Sukhdev Singh|\n",
      "|2021-03-30 03:30:...|You hate farmers ...|         0|           0|        1|         0|                null|\n",
      "|2021-03-30 03:29:...|They can't be far...|         0|           0|        0|         0|   Abhimanyu ðŸŒ ðŸ‡®ðŸ‡³|\n",
      "|2021-03-30 03:29:...|They can't be far...|         0|           0|        0|         0|   Abhimanyu ðŸŒ ðŸ‡®ðŸ‡³|\n",
      "|2021-03-30 03:28:...|Lets not forget t...|         0|           2|        3|         0|       Japneet Singh|\n",
      "|2021-03-30 03:28:...|@Troll48611422 @D...|         1|           0|        0|         0|                null|\n",
      "|2021-03-30 03:28:...|Neutrality helps ...|         0|           0|        0|         0|       Kisan BotðŸšœðŸŒ¾|\n",
      "|2021-03-30 03:28:...|Why You Should Vi...|         0|           0|        0|         0|    Saroj Bhardwaj î¨€|\n",
      "|2021-03-30 03:27:...|Stop asking God t...|         0|           0|        0|         0|    Jassu ðŸ‡®ðŸ‡³ðŸ‡¨ðŸ‡¦ðŸŒ¾|\n",
      "|2021-03-30 03:27:...|Great read to gai...|         0|           0|        0|         0|                ishy|\n",
      "|2021-03-30 03:27:...|Great read to gai...|         0|           0|        0|         0|                ishy|\n",
      "|2021-03-30 03:27:...|Great read to gai...|         0|           0|        0|         0|                ishy|\n",
      "|2021-03-30 03:27:...|Great read to gai...|         0|           0|        0|         0|                ishy|\n",
      "|2021-03-30 03:27:...|Great read to gai...|         0|           0|        0|         0|                ishy|\n",
      "|2021-03-30 03:27:...|Great read to gai...|         0|           0|        0|         0|                ishy|\n",
      "|2021-03-30 03:27:...|Great read to gai...|         0|           0|        0|         0|                ishy|\n",
      "|2021-03-30 03:27:...|#à¤¹à¥‹à¤²à¥€_à¤•à¥‡_à¤°à¤‚à¤—_à¤•à¤¿à¤¸à¤¾...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:27:...|@iaminnocentkid Y...|         0|           0|        0|         0|     preetybhatty ðŸ’«|\n",
      "|2021-03-30 03:27:...|Start Love With F...|         0|           4|        4|         0|   ð‘ºð’‰ð’†ð’ð’ð’š ðŸ‡®ðŸ‡³|\n",
      "|2021-03-30 03:26:...|Love the picture ...|         0|           0|        0|         0|               JassG|\n",
      "|2021-03-30 03:26:...|So much suffering...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:26:...|The true definati...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:26:...|@dil_di_awaz Dont...|         0|           0|        0|         0|       Enlightenment|\n",
      "|2021-03-30 03:26:...|@dil_di_awaz Dont...|         0|           0|        0|         0|       Enlightenment|\n",
      "|2021-03-30 03:26:...|@dil_di_awaz Dont...|         0|           0|        0|         0|       Enlightenment|\n",
      "|2021-03-30 03:26:...|@dil_di_awaz Dont...|         0|           0|        0|         0|       Enlightenment|\n",
      "|2021-03-30 03:26:...|@dil_di_awaz Dont...|         0|           0|        0|         0|       Enlightenment|\n",
      "|2021-03-30 03:26:...|@dil_di_awaz Dont...|         0|           0|        0|         0|       Enlightenment|\n",
      "|2021-03-30 03:26:...|@dil_di_awaz Dont...|         0|           0|        0|         0|       Enlightenment|\n",
      "|2021-03-30 03:26:...|@dil_di_awaz Dont...|         0|           0|        0|         0|       Enlightenment|\n",
      "|2021-03-30 03:25:...|Instead of listen...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:25:...|No caption needed...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:25:...|Farmers are doing...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:25:...|No caption needed...|         0|           1|        2|         0|    Harkesh Dhankhar|\n",
      "|2021-03-30 03:24:...|Farmers fighting ...|         0|           0|        0|         0|Satinder Kaur Ben...|\n",
      "|2021-03-30 03:24:...|#FarmersProtest  ...|         0|           1|        1|         0|                null|\n",
      "|2021-03-30 03:24:...|Word on the stree...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:24:...|Letâ€™s stand with ...|         0|           0|        1|         0|Satish Balsamand ...|\n",
      "|2021-03-30 03:24:...|Letâ€™s stand with ...|         0|           0|        1|         0|Satish Balsamand ...|\n",
      "|2021-03-30 03:24:...|Letâ€™s stand with ...|         0|           0|        1|         0|Satish Balsamand ...|\n",
      "|2021-03-30 03:24:...|Letâ€™s stand with ...|         0|           0|        1|         0|Satish Balsamand ...|\n",
      "|2021-03-30 03:24:...|Letâ€™s stand with ...|         0|           0|        1|         0|Satish Balsamand ...|\n",
      "|2021-03-30 03:24:...|Letâ€™s stand with ...|         0|           0|        1|         0|Satish Balsamand ...|\n",
      "|2021-03-30 03:24:...|Letâ€™s stand with ...|         0|           0|        1|         0|Satish Balsamand ...|\n",
      "|2021-03-30 03:24:...|farmers are askin...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:24:...|@jasdhaliwal349 L...|         0|           0|        1|         0|        Kay Vee, PhD|\n",
      "|2021-03-30 03:24:...|@jasdhaliwal349 L...|         0|           0|        1|         0|        Kay Vee, PhD|\n",
      "|2021-03-30 03:24:...|@jasdhaliwal349 L...|         0|           0|        1|         0|        Kay Vee, PhD|\n",
      "|2021-03-30 03:24:...|@jasdhaliwal349 L...|         0|           0|        1|         0|        Kay Vee, PhD|\n",
      "|2021-03-30 03:24:...|@jasdhaliwal349 L...|         0|           0|        1|         0|        Kay Vee, PhD|\n",
      "|2021-03-30 03:24:...|@jasdhaliwal349 L...|         0|           0|        1|         0|        Kay Vee, PhD|\n",
      "|2021-03-30 03:24:...|Modi wants to mak...|         0|           1|        1|         0|                ishy|\n",
      "|2021-03-30 03:24:...|Modi wants to mak...|         0|           1|        1|         0|                ishy|\n",
      "|2021-03-30 03:24:...|Modi wants to mak...|         0|           1|        1|         0|                ishy|\n",
      "|2021-03-30 03:24:...|Modi wants to mak...|         0|           1|        1|         0|                ishy|\n",
      "|2021-03-30 03:24:...|Modi wants to mak...|         0|           1|        1|         0|                ishy|\n",
      "|2021-03-30 03:24:...|Modi wants to mak...|         0|           1|        1|         0|                ishy|\n",
      "|2021-03-30 03:24:...|Modi wants to mak...|         0|           1|        1|         0|                ishy|\n",
      "|2021-03-30 03:23:...|#StopHateAgainstF...|         0|           8|        5|         0|       Sukhdev Singh|\n",
      "|2021-03-30 03:23:...|A #Hindu MLA was ...|         2|           0|        0|         0|                null|\n",
      "|2021-03-30 03:23:...|@ikaur_deep On it...|         0|           3|        2|         0|  The Pacifist Rebel|\n",
      "|2021-03-30 03:23:...|Trending on No :-...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:22:...|When dictatorship...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:22:...|#StopHateAgainstF...|         0|           0|        0|         0|        Atrij Kasera|\n",
      "|2021-03-30 03:22:...|#StopHateAgainstF...|         0|           0|        0|         0|        Atrij Kasera|\n",
      "|2021-03-30 03:22:...|#StopHateAgainstF...|         0|           0|        0|         0|        Atrij Kasera|\n",
      "|2021-03-30 03:22:...|#StopHateAgainstF...|         0|           0|        0|         0|        Atrij Kasera|\n",
      "|2021-03-30 03:22:...|#StopHateAgainstF...|         0|           0|        0|         0|        Atrij Kasera|\n",
      "|2021-03-30 03:22:...|#StopHateAgainstF...|         0|           0|        0|         0|        Atrij Kasera|\n",
      "|2021-03-30 03:22:...|Dear bhakts we ha...|         0|           2|        3|         0|                null|\n",
      "|2021-03-30 03:22:...|Stop Hating Farme...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:21:...|This Fascist Regi...|         0|           2|        2|         0|â˜¬ ð•µð–†ð–™ð–Žð–“ð–‰ð–Š?...|\n",
      "|2021-03-30 03:21:...|This Fascist Regi...|         0|           2|        2|         0|â˜¬ ð•µð–†ð–™ð–Žð–“ð–‰ð–Š?...|\n",
      "|2021-03-30 03:21:...|This Fascist Regi...|         0|           2|        2|         0|â˜¬ ð•µð–†ð–™ð–Žð–“ð–‰ð–Š?...|\n",
      "|2021-03-30 03:21:...|This Fascist Regi...|         0|           2|        2|         0|â˜¬ ð•µð–†ð–™ð–Žð–“ð–‰ð–Š?...|\n",
      "|2021-03-30 03:21:...|This Fascist Regi...|         0|           2|        2|         0|â˜¬ ð•µð–†ð–™ð–Žð–“ð–‰ð–Š?...|\n",
      "|2021-03-30 03:21:...|This Fascist Regi...|         0|           2|        2|         0|â˜¬ ð•µð–†ð–™ð–Žð–“ð–‰ð–Š?...|\n",
      "|2021-03-30 03:21:...|This Fascist Regi...|         0|           2|        2|         0|â˜¬ ð•µð–†ð–™ð–Žð–“ð–‰ð–Š?...|\n",
      "|2021-03-30 03:21:...|This Fascist Regi...|         0|           2|        2|         0|â˜¬ ð•µð–†ð–™ð–Žð–“ð–‰ð–Š?...|\n",
      "|2021-03-30 03:21:...|Farmers deserve r...|         0|           0|        0|         0|               Rkaur|\n",
      "|2021-03-30 03:21:...|Farmers are doing...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:21:...|Why does the bjp ...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:21:...|Kindness. The onl...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:21:...|We want the BJP g...|         0|           0|        0|         0|                null|\n",
      "|2021-03-30 03:21:...|Instead of listen...|         0|           2|        1|         0|                null|\n",
      "|2021-03-30 03:21:...|@Prabhjo45866124 ...|         1|           0|        0|         0|revolution save #...|\n",
      "|2021-03-30 03:20:...|You hate farmers ...|         1|          21|       17|         0|                null|\n",
      "|2021-03-30 03:20:...|In addition to re...|         0|           9|        5|         0|       Navneet Jammu|\n",
      "|2021-03-30 03:20:...|In addition to re...|         0|           9|        5|         0|       Navneet Jammu|\n",
      "|2021-03-30 03:20:...|In addition to re...|         0|           9|        5|         0|       Navneet Jammu|\n",
      "|2021-03-30 03:20:...|In addition to re...|         0|           9|        5|         0|             Navneet|\n",
      "|2021-03-30 03:20:...|In addition to re...|         0|           9|        5|         0|             Navneet|\n",
      "|2021-03-30 03:20:...|In addition to re...|         0|           9|        5|         0|             Navneet|\n",
      "|2021-03-30 03:20:...|In addition to re...|         0|           9|        5|         0|             Navneet|\n",
      "|2021-03-30 03:20:...|In addition to re...|         0|           9|        5|         0|             Navneet|\n",
      "|2021-03-30 03:20:...|In addition to re...|         0|           9|        5|         0|             Navneet|\n",
      "|2021-03-30 03:20:...|#FarmersProtest i...|         0|           0|        1|         0|                null|\n",
      "+--------------------+--------------------+----------+------------+---------+----------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the contents of the DataFrame.\n",
    "df_spark.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d4555",
   "metadata": {},
   "source": [
    "Using 'SparkSession.builder' I created a new SparkSession for interacting with Spark functionality. Then I created a new PySpark DataFrame by importing the 'new_tweets.csv' file which is stored in HDFS's 'ca2' directory. \n",
    "\n",
    "And now before I start examination and cleaning process of the newly created DataFrame, I would like to remove duplicates and NaN value rows from the DataFrame. As can be seen from the above cell, there are some NaN values in the new merged column 'displayname'. It seems like some users that tweeted on the twitter doesn't have a Display Name. It might indicate that they no longer user of the social media plaform, or even might have blocked becuse of trolling or whatever reason the account might have been deleted. So to prevent the bias and also to not waste my memory for extra processing I have decided to drop the rows which doesn't contain the display name or contain duplicate tweet entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7549481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the duplicates.\n",
    "df_spark = df_spark.drop_duplicates()\n",
    "\n",
    "# Dropping rows with null values in the column 'displayname'.\n",
    "df_spark = df_spark.filter(col('displayname').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "919c528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+------------+---------+----------+--------------------+\n",
      "|                date|     renderedContent|replyCount|retweetCount|likeCount|quoteCount|         displayname|\n",
      "+--------------------+--------------------+----------+------------+---------+----------+--------------------+\n",
      "|2020-11-01 03:36:...|Yesterday in a pu...|         8|          95|      389|         5|Manickam Tagore ....|\n",
      "|2020-11-01 10:54:...|Has this been rep...|         0|           0|        1|         0|        ClaireDeLune|\n",
      "|2020-11-01 12:10:...|Such a shame!\\n\\n...|         0|           0|        2|         0|          Rajay Deep|\n",
      "|2020-11-01 23:55:...|@WhiteHouse @real...|         1|           0|        3|         0|          OnTheFritz|\n",
      "|2020-11-02 02:28:...|Other side of APM...|         0|           0|        1|         0|Fateh Singh  Bhullar|\n",
      "|2020-11-02 06:59:...|Given #FarmersPro...|         0|           0|        0|         0|IndoAsianCommodities|\n",
      "|2020-11-02 14:42:...|.@asadowaisi \\nTh...|         0|           0|        0|         0|     pravingandhino1|\n",
      "|2020-11-02 15:06:...|@narendramodi Ver...|         0|           0|        0|         0|   Vishal Maheshwari|\n",
      "|2020-11-02 16:33:...|#GujjarReservatio...|         0|           0|        1|         0|         Bimal Jaggi|\n",
      "|2020-11-03 04:32:...|signature campaig...|         0|           0|        1|         0|         Rajan kumar|\n",
      "|2020-11-03 06:14:...|The Fence Eating ...|         0|           0|        0|         0|ðŸ‡®ðŸ‡³ Vinay VS ðŸ™ˆðŸ™‰ðŸ™Š|\n",
      "|2020-11-03 10:09:...|Gone are the days...|         0|           0|        0|         0| Salahuddin Siddiqui|\n",
      "|2020-11-03 12:50:...|They are essentia...|         1|           1|        2|         0|Taunton Deane Lib...|\n",
      "|2020-11-03 12:52:...|Sorry to say bt M...|         0|           1|        0|         0|Saikat DasðŸ‡®ðŸ‡³ #R...|\n",
      "|2020-11-03 13:12:...|@neeleshmisra @Ga...|         0|           0|        0|         0|             jaswant|\n",
      "|2020-11-03 17:07:...|Testing times ahe...|         0|           0|        1|         0|Tajiinder Singh |...|\n",
      "|2020-11-03 17:07:...|Testing times ahe...|         0|           0|        1|         0|Tajinder Singh | ...|\n",
      "|2020-11-03 19:39:...|The Congress in T...|         0|           0|        0|         0|             DT Next|\n",
      "|2020-11-03 22:17:...|You must always k...|         0|           0|        0|         0|Philip J Reynolds...|\n",
      "|2020-11-04 04:13:...|#pollution \\n#env...|         1|           0|        0|         0|   Archna Panjrattan|\n",
      "|2020-11-04 06:56:...|Punjab CM @capt_a...|         0|           0|        2|         0|      Tauseef Sheikh|\n",
      "|2020-11-04 07:12:...|Farmers need to g...|         0|           0|        5|         0|            RJ Fahad|\n",
      "|2020-11-04 08:25:...|#Punjab farm prot...|         1|           4|       15|         1|   Business Standard|\n",
      "|2020-11-04 08:34:...|This wouldnâ€™t hav...|         0|           0|        0|         0|              Gill â˜¬|\n",
      "|2020-11-04 08:45:...|.@capt_amarinder ...|         0|           0|        0|         0|     pravingandhino1|\n",
      "|2020-11-04 09:04:...|.@capt_amarinder ...|         1|           0|        0|         0|     pravingandhino1|\n",
      "|2020-11-04 09:27:...|#Railways lose Rs...|         0|          10|       37|         0|     Greater Kashmir|\n",
      "|2020-11-04 11:06:...|From vacating rai...|         0|           0|        2|         0|à¨ªà©€à¨Ÿà©€à¨¸à©€ à¨¨à¨¿à¨Šà©› | PTC...|\n",
      "|2020-11-04 13:03:...|Most condemnable ...|        17|          86|      363|         4|   Shazia Atta Marri|\n",
      "|2020-11-04 13:17:...|This thread on an...|         0|           0|        0|         0|    Pracheta Budhwar|\n",
      "|2020-11-04 13:44:...|This is so import...|         0|           2|        2|         0|Taunton Deane Lib...|\n",
      "|2020-11-04 14:33:...|.@AiksccOriginal_...|         0|           0|        0|         0|        Rakesh Raman|\n",
      "|2020-11-04 15:34:...|@India_Policy Nev...|         0|           0|        1|         0|       pyara dilawar|\n",
      "|2020-11-04 18:02:...|#EiSamay 21 farme...|         0|           0|        0|         0|      prasenjit bera|\n",
      "|2020-11-04 18:41:...|Central Farm Laws...|         0|           0|        0|         0|          SIKH ISSUE|\n",
      "|2020-11-04 18:42:...|The Indian Expres...|         0|           0|        0|         0|          SIKH ISSUE|\n",
      "|2020-11-04 18:54:...|The Tribune India...|         0|           0|        0|         0|          SIKH ISSUE|\n",
      "|2020-11-04 19:30:...|The Mandi Act pas...|         0|           1|        0|         0|   MeenaÙ…ÙÛŒÙ’Ù†ÙŽØ§Ù’à¤®à¥€à¤¨à¤¾|\n",
      "|2020-11-04 19:44:...|A Journalist gets...|         0|           0|        4|         0|         J S Maan âš“ï¸|\n",
      "|2020-11-04 20:12:...|#FarmersProtest v...|         0|           0|        0|         0|Matt Anderson ðŸ‡ª?...|\n",
      "|2020-11-05 02:29:...|@OpIndia_com @Raj...|         0|           0|        1|         0|Ratnesh A Desai (...|\n",
      "|2020-11-05 02:35:...|Punjab farm prote...|         0|           1|        9|         0|   Business Standard|\n",
      "|2020-11-05 04:08:...|#Congress signatu...|         0|           1|        6|         1|Malyala Sujith Kumar|\n",
      "|2020-11-05 04:28:...|@IndianExpress Go...|         0|           0|        0|         0|     Parvinder Singh|\n",
      "|2020-11-05 04:33:...|#chakkajam today....|         0|           0|        0|         0|Gurdev Singh Sukh...|\n",
      "|2020-11-05 04:54:...|#Chakkajamtoday :...|         0|           0|        3|         0|à¨ªà©€à¨Ÿà©€à¨¸à©€ à¨¨à¨¿à¨Šà©› | PTC...|\n",
      "|2020-11-05 06:35:...|Punjab farm prote...|         0|           1|        6|         0|   Business Standard|\n",
      "|2020-11-05 07:35:...|#Chakkajam today:...|         0|           0|        0|         0|à¨ªà©€à¨Ÿà©€à¨¸à©€ à¨¨à¨¿à¨Šà©› | PTC...|\n",
      "|2020-11-05 08:00:...|#Punjab farm prot...|         0|           3|        9|         0|   Business Standard|\n",
      "|2020-11-05 08:20:...|@AmitShah ðŸ˜ Amit...|         0|           0|        0|         0|  SAMYUKAT CHAUDHARY|\n",
      "|2020-11-05 09:00:...|Human rights acti...|         0|           0|        0|         0|     UCAN  Indonesia|\n",
      "|2020-11-05 09:00:...|Human rights acti...|         0|           0|        0|         0|      UCAN Sri Lanka|\n",
      "|2020-11-05 09:00:...|Human rights acti...|         0|           0|        0|         0|          UCAN India|\n",
      "|2020-11-05 10:16:...|#Punjab BJP leade...|         0|           0|        0|         0|à¨ªà©€à¨Ÿà©€à¨¸à©€ à¨¨à¨¿à¨Šà©› | PTC...|\n",
      "|2020-11-05 10:19:...|Just awful...ðŸ˜¡\\n...|         0|           1|        2|         0|Somerset Liberal ...|\n",
      "|2020-11-05 12:56:...|â€œWe have agreed t...|         0|           0|        1|         0|  The Logical Indian|\n",
      "|2020-11-05 13:15:...|#Pakistan #People...|         0|           0|        0|         0|Khalid Mahmood Kh...|\n",
      "|2020-11-05 13:28:...|@manaman_chhina @...|         0|           2|        7|         0|         arvind ðŸ‡®ðŸ‡³|\n",
      "|2020-11-05 13:28:...|@manaman_chhina @...|         0|           2|        7|         0|              arvind|\n",
      "|2020-11-05 13:54:...|@Shiffa_ZY A comp...|         0|           0|        0|         0|          ðŸ‘©â€ðŸŽ“qurat|\n",
      "|2020-11-05 14:00:...|Damn #PunjabPolic...|         0|           0|        1|         0|          ðŸ‘©â€ðŸŽ“qurat|\n",
      "|2020-11-05 14:05:...|@HamidMirPAK How ...|         0|           0|        0|         0|          ðŸ‘©â€ðŸŽ“qurat|\n",
      "|2020-11-05 14:10:...|@HamidMirPAK Punj...|         0|           0|        0|         0|          ðŸ‘©â€ðŸŽ“qurat|\n",
      "|2020-11-05 14:13:...|#PoliticsOverTrai...|         0|           5|        6|         0|        Jagtar Singh|\n",
      "|2020-11-05 14:14:...|All crops in Punj...|         0|           0|        1|         0|        India Blooms|\n",
      "|2020-11-05 14:37:...|How India Was Str...|         0|           0|        0|         0|                 BSS|\n",
      "|2020-11-05 15:33:...|@asmashirazi I ne...|         0|           0|        1|         0|          ðŸ‘©â€ðŸŽ“qurat|\n",
      "|2020-11-05 15:39:...|The Punjab govt i...|         1|           0|       11|         0|        moneycontrol|\n",
      "|2020-11-05 15:58:...|Reliable and rele...|         0|           6|       14|         0|     Uday Bhan Singh|\n",
      "|2020-11-05 17:42:...|How do we quantif...|         0|           0|        1|         0|     Gagandeep Ahuja|\n",
      "|2020-11-05 18:02:...|@BBCUrdu Media in...|         0|           0|        1|         0|          ðŸ‘©â€ðŸŽ“qurat|\n",
      "|2020-11-05 18:18:...|Heart bleeds afte...|         0|           0|        2|         0|      Naurez Hasnain|\n",
      "|2020-11-05 18:30:...|#punjab is gradua...|         0|           0|        1|         0|     Amardeep S Reen|\n",
      "|2020-11-06 01:46:...|@ndtv Atleast Mr....|         0|           0|        1|         0|            dp ðŸ¹ ðŸšœ|\n",
      "|2020-11-06 03:47:...|Farmers put up ro...|         0|           0|        0|         0|     Indian Advocate|\n",
      "|2020-11-06 03:52:...|Rise âœŠðŸ½âœŠðŸ½\\n#Far...|         0|           0|        2|         0|             Megha S|\n",
      "|2020-11-06 03:52:...|Rise âœŠðŸ½âœŠðŸ½\\n#Far...|         0|           0|        2|         0|         Megha Sheth|\n",
      "|2020-11-06 03:59:...|What else could h...|         0|           0|        3|         0|          Rajay Deep|\n",
      "|2020-11-06 05:35:...|It's horrifying &...|         5|          38|      103|         3| Sukhbir Singh Badal|\n",
      "|2020-11-06 06:46:...|BJP govt. messed ...|         0|           0|        0|         0| Shreelakshmi Dinesh|\n",
      "|2020-11-06 07:34:...|This is a farmers...|         0|           9|       46|         1|    CPIML Liberation|\n",
      "|2020-11-06 07:51:...|#Ludhiana halts f...|         0|           1|        3|         0|        mohit khanna|\n",
      "|2020-11-06 09:58:...|#JustIn: There ar...|         0|           0|        6|         0|        moneycontrol|\n",
      "|2020-11-06 10:29:...|Visited paddy pro...|         0|           0|        3|         0|Malyala Sujith Kumar|\n",
      "|2020-11-06 11:14:...|There is somethin...|         8|          91|      241|        10|     Devinder Sharma|\n",
      "|2020-11-06 11:19:...|Protest Against F...|         0|           0|        0|         0|             LokMarg|\n",
      "|2020-11-06 12:02:...|Bitter Truth #Far...|         0|           0|        1|         0|      RAJDEEP PAREEK|\n",
      "|2020-11-06 12:34:...|#Congress signatu...|         0|           1|        3|         0|Malyala Sujith Kumar|\n",
      "|2020-11-06 12:57:...|Finally, #Punjab ...|         0|           0|        8|         0|         The Tribune|\n",
      "|2020-11-06 14:05:...|#FarmersProtest #...|         1|           1|        8|         0|         The Tribune|\n",
      "|2020-11-06 16:27:...|@IndiaToday Mr. P...|         0|           0|        1|         0|Gurdev Singh Sukh...|\n",
      "|2020-11-07 03:17:...|.@capt_amarinder ...|         0|           0|        0|         0|     pravingandhino1|\n",
      "|2020-11-07 03:20:...|Hasnt the Supreme...|         0|           0|        0|         0|     pravingandhino1|\n",
      "|2020-11-07 03:27:...|.@PiyushGoyal @Ra...|         0|           0|        0|         0|     pravingandhino1|\n",
      "|2020-11-07 06:28:...|Biogas plant will...|         0|           0|        0|         0|          India Post|\n",
      "|2020-11-07 10:29:...|On November 5, #f...|         0|           3|        5|         0|     National Herald|\n",
      "|2020-11-07 15:16:...|It's horrifying &...|         0|           0|        0|         0|  Gurpreet S Khalsaâ„¢|\n",
      "|2020-11-07 19:13:...|If one train deli...|         0|           0|        0|         1|      Urooj Khan TOI|\n",
      "|2020-11-08 18:32:...|I am surprised @r...|         0|           0|        0|         0|          BITTERMINT|\n",
      "|2020-11-08 18:32:...|I am surprised @r...|         0|           0|        0|         0|Dont Lock Justice...|\n",
      "+--------------------+--------------------+----------+------------+---------+----------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Checking the contents of the DataFrame.\n",
    "df_spark.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fabe56c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 1082432\n",
      "Number of columns: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the DataFrame\n",
    "print('Number of rows:', df_spark.count())\n",
    "print('Number of columns:', len(df_spark.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2441f421",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- renderedContent: string (nullable = true)\n",
      " |-- replyCount: string (nullable = true)\n",
      " |-- retweetCount: string (nullable = true)\n",
      " |-- likeCount: string (nullable = true)\n",
      " |-- quoteCount: string (nullable = true)\n",
      " |-- displayname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking column dtypes.\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8122ee",
   "metadata": {},
   "source": [
    "The I can see from above exicuted examination that there are some columns has to be renamed and thier dtypes has to be changed to the proper dtypes. Furthemore, for column 'renderedContent' there has to be done some cleaning (removing tags, hashtags, emails, and links). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e22aa21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Renaming the columns.\n",
    "df_spark = df_spark.select(col('date').alias('date'),\n",
    "                           col('renderedContent').alias('tweet'),\n",
    "                           col('displayname').alias('user'),\n",
    "                           col('replyCount').alias('replied'),\n",
    "                           col('retweetCount').alias('retweeted'),\n",
    "                           col('likeCount').alias('liked'),\n",
    "                           col('quoteCount').alias('quoted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e17110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing dtypes.\n",
    "df_spark = df_spark.withColumn('date',to_date(col('date').cast(DateType())))\n",
    "df_spark = df_spark.withColumn('tweet',col('tweet').cast(StringType()))\n",
    "df_spark = df_spark.withColumn('user',col('user').cast(StringType()))\n",
    "df_spark = df_spark.withColumn('replied',col('replied').cast('integer'))\n",
    "df_spark = df_spark.withColumn('retweeted',col('retweeted').cast('integer'))\n",
    "df_spark = df_spark.withColumn('liked',col('liked').cast('integer'))\n",
    "df_spark = df_spark.withColumn('quoted',col('quoted').cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8de8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing tags, hashtags, emails, and website links from the values of the column 'tweet'.\n",
    "df_spark = df_spark.withColumn('tweet', regexp_replace('tweet', r'@\\w+|#\\S+|\\S+@\\S+|http\\S+|www\\S+|\\S+/\\S+', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298f54d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the contents of the DataFrame.\n",
    "df_spark.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c5455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the contents of the column \"renderedContent\".\n",
    "df_spark.select('tweet').show(100, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23015752",
   "metadata": {},
   "source": [
    "The DataFrame column names are changed and the dtypes for each column was set correctly. Also emails, links, tags, hashtags from The 'tweet' column values were successfully removed. However, from the above cell I can see that the  column 'tweet' still missing some cleaning. Further, I will remove leading and traling whitespaces and non-English texts from the string value of the column. Then, I'll replace two or more continous whitespaces with a single whitespace, and also, I'll replace the new line and tab with '.'. And lastly I'll lowercase the entire string for each column value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing leading and trailing whitespace from the values of the column 'tweet'.\n",
    "df_spark = df_spark.withColumn('tweet', trim(df_spark.tweet))\n",
    "\n",
    "# Replacing two or more spaces to one from the values of the column 'tweet'.\n",
    "df_spark = df_spark.withColumn('tweet', regexp_replace('tweet', r'\\s{2,}', ' '))\n",
    "\n",
    "# Replacing new-line and tab to '.' from the values of the column 'tweet'.\n",
    "df_spark = df_spark.withColumn('tweet', regexp_replace('tweet', r'\\n|\\t', '.'))\n",
    "\n",
    "# Removing non-English text from the values of the column 'tweet'.\n",
    "df_spark = df_spark.withColumn('tweet', regexp_replace('tweet', \"[^a-zA-Z0-9!@#$%^&*()_+\\-={}\\[\\]|\\\\;:'\\\",.<>/?~` ]\", ''))\n",
    "\n",
    "# Lowercasing all the values of the column 'tweet'.\n",
    "df_spark = df_spark.withColumn('tweet', lower(df_spark.tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d6f88a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_spark.select('tweet').show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a19d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08fa2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80509fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.orderBy('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae87e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ea3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cacea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_spark.groupBy('user').count().sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.collect()[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7007f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c84e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_spark.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('select * from tweet').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d4922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
